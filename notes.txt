########################################
########## HELPFUL COMMANDS
########################################

show dbs                     	show database names
show collections             	show collections in current database
show users                   	show users in current database
db.getName();					Get current database name
use <db_name>					Set current database
db.dropDatabase();				Delete/drop current database
show collections				Show the collections contained in the current database

mvn clean compile exec:java -Dexec.mainClass=com.mongdb.App

> docker run -it -p 27017:27017 --name myMongo -d mongo
> docker exec -it myMongo mongo

########################################
########## WEEK 2 - CRUD
#### TOPICS: Mongo Shell, Query Operators, Update Operators and a Few Commands

##### Creating documents

mongorestore dump
insertOne();
insertMany();
UPDATE COMMANDS is known as "upserts".

##### The _id Field

All collections have a unique primary index on the _id field by default.

			Date    MAC		PID		Counter
ObjectId: _ _ _ _ | _ _ _ | _ _ | _ _ _
12-Byte Hex String

Date - Current time stamp
MAC - The MAC address for the machine on which the MongoDB server is running.
PID - Process ID.
Counter - A standard counter to make sure that the ObjectId is indeed unique.

Note that the "Date" label that refers to the first four bytes does in fact reference a UTC datetime with a precision of seconds (not days). When talking about BSON, this is distinct from a timestamp, which is a special internal data type used in MongoDB replication and sharding.

##### Reading documents

db.movieDetails.find({ rated: "PG-13" }).pretty();
db.movieDetails.find({ rated: "PG-13" }).count();
db.movieDetails.find({ rated: "PG-13", year: 2009 }).count();
db.movieDetails.find({ "tomato.meter": 100 }).count();
db.movieDetails.find({ "tomato.meter": 99 }).pretty();

// For this particular case the order of the elements matters
// So the writers array must have only two elements following the order which each one was inserted
db.movieDetails.find({ "writers": ["Ethan Coen", "Joel Coen"] }).count();

// In this very case it will match all documents which have the actor "Jeff Bridges", thus this is not an exact match like the previous one
db.movieDetails.find({ "actors": "Jeff Bridges" }).pretty();

// All documents which have "Jeff Bridges" as the first element in actors array
db.movieDetails.find({ "actors.0": "Jeff Bridges" }).pretty();

// The find method returns a cursor. If you do the command below without assigning a variable to it, the cursor will automatically iterate up to 20 times.
db.movieDetails.find({ rated: "PG" }).pretty();

// Cursors

var c = db.movieDetails.find();
var doc = function() { return c.hasNext() ? c.next() : null; }
c.objsLeftInBatch(); // 101 documents in the initial batch
doc() // to iterate using the cursor
c.objsLeftInBatch(); // if will do the command again it will return 100 documents

// Projectinos

// It will include only the attribute title and exclude _id
db.movieDetails.find({ rated: "PG" }, { title: 1, _id: 0 } ).pretty();

// It will include all fields except for the ones explicity excluded below
db.movieDetails.find( { rated: "PG" }, { writers: 0, actors: 0, _id: 0 } ).pretty();

##### Comparison operators

// More details at https://docs.mongodb.com/manual/reference/operator/query-comparison/

// All movies that have a runtime greater than 90
db.movieDetails.find({ runtime: { $gt: 90 } }).pretty();
db.movieDetails.find({ runtime: { $gt: 90 } }).count();
db.movieDetails.find({ runtime: { $gt: 90 } }, { title: 1, runtime: 1, _id: 0 }).pretty();
// Greater than or equal to 90 and less than or equal to 120. It means: (runtime >= 90 && runtime <= 120)
db.movieDetails.find({ runtime: { $gte: 90, $lte: 120 } }, { title: 1, runtime: 1, _id: 0 }).pretty();
db.movieDetails.find({ "tomato.meter": { $gte: 95 }, runtime: { $gt: 180 } }, { title: 1, runtime: 1, _id: 0 }).pretty();
db.movieDetails.find({ rated: { $ne: "UNRATED" } }, { title: 1, runtime: 1, _id: 0 }).count();
// Return all the documents where the value of rated is G or PG
db.movieDetails.find({ rated: { $in: ["G", "PG"] } }, { title: 1, runtime: 1, _id: 0 }).count();
// The reverse statement of the prepostion above
db.movieDetails.find({ rated: { $nin: ["G", "PG"] } }, { title: 1, runtime: 1, _id: 0 }).count();

##### Element operators

// It verifies if there are documents which have tomate.meter field
db.movieDetails.find({ "tomato.meter": { $exists: true } }).count();

db.moviesScratch.find({ _id: { $type: "string" } }).pretty();
// We can count how many documents are stored with _id as String and so on
db.moviesScratch.find({ _id: { $type: "string" } }).count();
db.moviesScratch.find({ _id: { $type: "objectId" } }).pretty();

##### Logical operators

// More details at https://docs.mongodb.com/manual/reference/operator/query-logical/

// $or takes an array as an argument
db.movieDetails.find({ $or : [ { "tomato.meter": { $gt: 99 } },
                               { "metacritic": { $gt: 95 } } ] }).count();

// $and is used when we need to specify multiple criteria on the same field							   
db.movieDetails.find({ $and : [ { "metacritic": { $ne: null } },
                               { "metacritic": { $exists: true } } ] }).count();
							   
##### Regex operator

// Return all the documents which have awards.text field started by the word "Won ". "\s" means "space".
db.movieDetails.find({ "awards.text": { $regex: /^Won\s.*/ } }).pretty()

##### Array operators

// More details at https://docs.mongodb.com/manual/reference/operator/query-array/

// Return all documents which have comedy, crime and drame in their genres field.
db.movieDetails.find({ genres: { $all: ["Comedy", "Crime", "Drama"] } }).pretty()	

// This is entire different from the example using $elemMatch because it won't try by each element contained in the array.
// Actually each field will be evaluated individually
db.movieDetails.find({ boxOffice: { country: "UK", revenue: { $gt: 15 } } })

db.movieDetails.find({ boxOffice: {$elemMatch: { country: "UK", revenue: { $gt: 15 } } } })

##### Updating documents

// Update any document that has imbd.id equal to detail.imdb.id
// Replace the document with detail
// If this filter doesn't match any document in my collection, so I want to go ahead and create a new one, with a new _id
db.movieDetails.updateOne(
	{ "imbd.id" : detail.imdb.id },
	{ $set : detail },
	{ upsert: true }
)

##### Homework 2.1

mvn compile exec:java -Dexec.mainClass=course.homework.MongoDBSparkFreemarkerStyle

##### Homework 2.2

mongoimport -d students -c grades < grades.json
use students
db.grades.count() // You should get 800.
// The student_id with the highest average score
db.grades.aggregate({'$group':{'_id':'$student_id', 'average':{$avg:'$score'}}}, {'$sort':{'average':-1}}, {'$limit':1})
// All exam scores greater than or equal to 65, and sort those scores from lowest to highest.
db.grades.find({ score: { $gte: 65 } }).sort({ 'score': 1 });

##### Homework 2.3

// Sort student by its identity and limit the query to 12
db.grades.find().sort({'student_id' : 1}).limit(12);

// Remove the grade of type "homework" with the lowest score for each student from the dataset in the handout. 
// Since each document is one grade, it should remove one document per student. Sample:
/*
> db.grades.find({"student_id" : 0})
{ "_id" : ObjectId("50906d7fa3c412bb040eb577"), "student_id" : 0, "type" : "exam", "score" : 54.6535436362647 }
{ "_id" : ObjectId("50906d7fa3c412bb040eb579"), "student_id" : 0, "type" : "homework", "score" : 14.8504576811645 }
{ "_id" : ObjectId("50906d7fa3c412bb040eb578"), "student_id" : 0, "type" : "quiz", "score" : 31.95004496742112 }
{ "_id" : ObjectId("50906d7fa3c412bb040eb57a"), "student_id" : 0, "type" : "homework", "score" : 63.98402553675503 }
*/

db.grades.aggregate(
	{
		"$match" : { "type" : "homework" }
	},
	{
		'$group': {
		'_id' : { student_id : "$student_id", type : "$type" },
		'min' : { '$min' : '$score' }
		}
	}, 
	{'$sort':{'_id':-1}}, 
	{'$limit':1});

// The result should be 600. Now let us find the student who holds the 101st best grade across all grades:
db.grades.find().sort( { 'score' : -1 } ).skip( 100 ).limit( 1 )	
// Now let us sort the students by student_id , and score, while also displaying the type to then see what the top five docs are:
db.grades.find( { }, { 'student_id' : 1, 'type' : 1, 'score' : 1, '_id' : 0 } ).sort( { 'student_id' : 1, 'score' : 1 } ).limit( 5 )
// The identity of the student with the highest average in the class
db.grades.aggregate( { '$group' : { '_id' : '$student_id', 'average' : { $avg : '$score' } } }, { '$sort' : { 'average' : -1 } }, { '$limit' : 1 } )
	
##### Homework 2.5

// Which of the choices below is the title of a movie from the year 2013 that is rated PG-13 and won no awards?

db.movieDetails.find({ "rated": "PG-13", "year": 2013, "awards.wins": 0})	

##### Homework 2.6

// Using the video.movieDetails collection, how many movies list "Sweden" second in the the list of countries.

db.movieDetails.find({ "countries.1": "Sweden" })	

########################################
########## WEEK 3 - SCHEMA DESIGN
#### TOPICS: Patterns, Case Studies & Tradeoffs

// --------- Introduction

// https://en.wikipedia.org/wiki/Third_normal_form

// Application driven schema

MongoDB keys: 
	1 - Rich documents
	2 - Pre Join / Embed Data
	3 - No Mongo Joins - it doesn't support joins directly inside de kernel, you must do it inside de application
	4 - There are no constraints
	5 - Atomic operations - MongoDB doesn't support transactions, but it does support atomic operations within one document.
	6 - No declared schema

What's the single most important factor in designing your application schema within MongoDB?
A: Matching the data access patterns of your application

What's the single most important factor in designing your application schema within MongoDB?
A: Matching the data access patterns of your application

// --------- Living wihout transactions

Restructure to create a single document and then make good use of atomic operations
Implement transaction in software like MongoDB critical section
And at last tolerate a little bit of inconsistency

Which of the following operations operate atomically within a single document? Check all that apply.
Update, findAndModify, $addToSet(within an update) and $push within an update

// --------- One to one relations

Frequency of access
Size of the items
Atomicity of data

// --------- One to many relations	

One modest type of one to many is when you think about people vs city situation. It's complicated to make a good relationship with MongoDB, true linking is one way to resolve it.

// --------- One to few relations	

It's like one to many, but a lot easier with MongoDB. Blog post vs comments is a typical  situation.

// --------- Many to many relations

Samples situations are books vs authors and students vs teachers. As you can see they are not truly many to many but few to few, so you can linking or embedding, of course you must evaluate pretty well which one best suits you.

// --------- Multikeys indexes

> db.students.find()
{ "_id" : 0, "name" : "Andrew Erlichson", "teachers" : [ 0, 1 ] }
{ "_id" : 1, "name" : "Richard Kreuter", "teachers" : [ 0, 1, 3 ] }
{ "_id" : 2, "name" : "Eliot Horowitz", "teachers" : [ 1, 2, 3 ] }
{ "_id" : 3, "name" : "Mark Heinrich", "teachers" : [ 0, 3 ] }
> db.teachers.find()
{ "_id" : 0, "name" : "Mark Horowitz" }
{ "_id" : 1, "name" : "John Hennessy" }
{ "_id" : 2, "name" : "Bruce Wolley" }
{ "_id" : 3, "name" : "James Plummer" }
> db.students.ensureIndex({ 'teachers' : 1 })
// All the students who had Mark Horowitz and John Hennessy as professors
> db.students.find({ 'teachers' : { $all : [0,1] } )
{ "_id" : 0, "name" : "Andrew Erlichson", "teachers" : [ 0, 1 ] }
{ "_id" : 1, "name" : "Richard Kreuter", "teachers" : [ 0, 1, 3 ] }
// How do we know that used an index?
> db.students.find({ 'teachers' : { $all : [0,1] } ).explain()

// --------- Benefits of embedding

The main benefit of embedding data from two different collections and bringing it together into one collection is performance.

- Improved read performance
- One round trip to the DB

// --------- Representing trees

https://docs.mongodb.com/manual/tutorial/model-tree-structures-with-ancestors-array/

Given the following typical document for a e-commerce category hierarchy collection called categories.

{
  _id: 34,
  name: "Snorkeling",
  parent_id: 12,
  ancestors: [12, 35, 90]
}

Which query will find all descendants of the snorkeling category?

db.categories.find({ ancestors : 34 })

// --------- ODM introduction

https://mongodb.github.io/morphia/

ODM means Object Document Mapper.

##### Homework 3.1

// Write a program in the language of your choice that will remove the lowest homework score for each student. Since there is a single document for each student containing an array of scores, you will need to update the scores array and remove the homework.

// Remember, just remove a homework score. Don't remove a quiz or an exam!

// Hint/spoiler: With the new schema, this problem is a lot harder and that is sort of the point. One way is to find the lowest homework in code and then update the scores array with the low homework pruned.

use school
db.students.count() // should return 200
db.students.find( { _id : 137 } ).pretty()

{
	"_id" : 137,
	"name" : "Tamika Schildgen",
	"scores" : [
		{
			"type" : "exam",
			"score" : 4.433956226109692
		},
		{
			"type" : "quiz",
			"score" : 65.50313785402548
		},
		{
			"type" : "homework",
			"score" : 89.5950384993947
		},
		{
			"type" : "homework",
			"score" : 54.75994689226145
		}
	]
}

db.students.find( { _id : 19 } ).pretty()

{
	"_id" : 19,
	"name" : "Gisela Levin",
	"scores" : [
		{
			"type" : "exam",
			"score" : 44.51211101958831
		},
		{
			"type" : "quiz",
			"score" : 0.6578497966368002
		},
		{
			"type" : "homework",
			"score" : 93.36341655949683
		},
		{
			"type" : "homework",
			"score" : 49.43132782777443
		}
	]
}

// Annotations

> db.students.aggregate([ {'$sort':{'_id':-1}},  {'$limit':4} ]);
{ "_id" : 199, "name" : "Rae Kohout", "scores" : [ { "type" : "exam", "score" : 82.11742562118049 }, { "type" : "quiz", "score" : 49.61
295450928224 }, { "type" : "homework", "score" : 28.86823689842918 }, { "type" : "homework", "score" : 5.861613903793295 } ] }
{ "_id" : 198, "name" : "Timothy Harrod", "scores" : [ { "type" : "exam", "score" : 11.9075674046519 }, { "type" : "quiz", "score" : 20
.51879961777022 }, { "type" : "homework", "score" : 55.85952928204192 }, { "type" : "homework", "score" : 64.85650354990375 } ] }
{ "_id" : 197, "name" : "Tonisha Games", "scores" : [ { "type" : "exam", "score" : 38.51269589995049 }, { "type" : "quiz", "score" : 31
.16287577231703 }, { "type" : "homework", "score" : 79.15856355963004 }, { "type" : "homework", "score" : 56.17504143517339 } ] }
{ "_id" : 196, "name" : "Santiago Dollins", "scores" : [ { "type" : "exam", "score" : 52.04052571137036 }, { "type" : "quiz", "score" :
 33.63300076481705 }, { "type" : "homework", "score" : 4.629511012591447 }, { "type" : "homework", "score" : 78.79257377604428 } ] }
 
// https://docs.mongodb.com/manual/reference/operator/aggregation/unwind/ 
 
> db.students.aggregate([ { $unwind: "$scores" }, {'$sort':{'_id':-1}},  {'$limit':4} ]);
{ "_id" : 199, "name" : "Rae Kohout", "scores" : { "type" : "homework", "score" : 5.861613903793295 } }
{ "_id" : 199, "name" : "Rae Kohout", "scores" : { "type" : "quiz", "score" : 49.61295450928224 } }
{ "_id" : 199, "name" : "Rae Kohout", "scores" : { "type" : "homework", "score" : 28.86823689842918 } }
{ "_id" : 199, "name" : "Rae Kohout", "scores" : { "type" : "exam", "score" : 82.11742562118049 } }

> db.students.aggregate([ { $unwind: "$scores" }, { $group: { '_id' : { _id : "$_id", type : "$scores.type" }, 'min' : { '$min' : '$scores.score' } } }, {'$sort':{'_id':-1}},  {'$limit':3} ]);
{ "_id" : { "_id" : 199, "type" : "quiz" }, "min" : 49.61295450928224 }
{ "_id" : { "_id" : 199, "type" : "homework" }, "min" : 5.861613903793295 }
{ "_id" : { "_id" : 199, "type" : "exam" }, "min" : 82.11742562118049 }

> db.students.aggregate([ { $unwind: "$scores" }, { $group: { '_id' : { _id : "$_id", type : "$scores.type" }, 'min' : { '$min' : '$scores.score' } } }, {'$sort':{'_id':-1}},  {'$limit':4} ]);
{ "_id" : { "_id" : 199, "type" : "quiz" }, "min" : 49.61295450928224 }
{ "_id" : { "_id" : 199, "type" : "homework" }, "min" : 5.861613903793295 }
{ "_id" : { "_id" : 199, "type" : "exam" }, "min" : 82.11742562118049 }
{ "_id" : { "_id" : 198, "type" : "quiz" }, "min" : 20.51879961777022 }

> db.students.aggregate([ { $unwind: "$scores" }, { $match : { "scores.type" : "homework" } }, { $group: { '_id' : { _id : "$_id", type: "$scores.type" }, 'min' : { '$min' : '$scores.score' } } }, {'$sort':{'_id':-1}},  {'$limit':4} ]);
{ "_id" : { "_id" : 199, "type" : "homework" }, "min" : 5.861613903793295 }
{ "_id" : { "_id" : 198, "type" : "homework" }, "min" : 55.85952928204192 }
{ "_id" : { "_id" : 197, "type" : "homework" }, "min" : 56.17504143517339 }
{ "_id" : { "_id" : 196, "type" : "homework" }, "min" : 4.629511012591447 }

db.students.aggregate([	
	{ $unwind: "$scores" },
	{ $match : { "scores.type" : "homework" } },
	{ $group: {
			'_id' : { _id : "$_id", type : "$scores.type" },
			'min' : { '$min' : '$scores.score' }
		}
	},	
	{'$sort':{'_id':-1}}, 
	{'$limit':1}
]);

https://docs.mongodb.com/manual/reference/operator/update/positional/#update-embedded-documents-using-multiple-field-matches
https://docs.mongodb.com/manual/reference/operator/update/pull/#remove-items-from-an-array-of-documents

db.students.find({ "_id": 199 })

db.students.update(
	{ "_id": 199 },
	{ $pull: { scores: { type: "homework" , score: 5.861613903793295 } } },
	{ multi: true }
)

// To verify that you have completed this task correctly, provide the identity (in the form of their _id) of the student with the highest average in the class with following query that uses the aggregation framework. The answer will appear in the _id field of the resulting document.

db.students.aggregate( [
  { '$unwind': '$scores' },
  {
    '$group':
    {
      '_id': '$_id',
      'average': { $avg: '$scores.score' }
    }
  },
  { '$sort': { 'average' : -1 } },
  { '$limit': 1 } ] )
  
########################################
########## WEEK 4 - PERFORMANCE  
#### TOPICS: Using Indexes, Monitoring And Understanding Performance. Performance In Sharded Environments

// --------- Storage Engines: Introduction

https://docs.mongodb.com/manual/core/storage-engines/

Main ways of performance:
	- Indexing
	- Sharding - Distributing database queries across multiple servers
	
Storage engine: It is located between MongoDB itself and for example a type of persistence storage like hard disk. It can use memory to storage data before send it to disk. If we compare to something real it's like a motor engine in your car, you can switch it for another when you like it to match some sort of requirement. MongoDB ships with two storage engines:
	- MMAP: It's the default for 3.0.
	- WiredTiger: It started to be the default on 3.2 --> https://docs.mongodb.com/manual/release-notes/3.2/#wiredtiger-as-default

The storage engine directly determines which of the following?
A: The data file format; Format of indexes.

// --------- Storage Engines: MMAPv1

1 - Collection level locking
2 - In place updates

http://docs.mongodb.org/manual/core/storage/?&_ga=2.176324003.721559069.1498430831-1068873678.1493258930#power-of-2-allocation

> man mmap // The description is "allocate memory, or map files or devices into memory"

Which of the following statements about the MMAPv1 storage engine are true? 
A: MMAPv1 automatically allocates power-of-two-sized documents when new documents are inserted; MMAPv1 is built on top of the mmap system call that maps files into memory.

Example that has record spaces allocated for as few as 4 bytes; in fact, the minimum record space in MongoDB 3.0 is 32 bytes.

// --------- Storage Engines: WiredTiger

1 - Document level concurrency
2 - Compressions of DATA and INDEXES
3 - No in place update

You can use this storage engine using -storageEngine. Sample:
> mongod -dbpath myCustomDir -storageEngine wiredTiger
> db.foo.insert({ name: 'Budega' })
> db.foo.stats(); // See the properties of the collection

Which of the following are features of the WiredTiger storage engine?
A: Document-level concurrency; Compression.

// --------- Indexes

https://docs.mongodb.com/manual/indexes/
https://en.wikipedia.org/wiki/B-tree -> A type of balanced search tree used frequently for indexing database tables

(a, b, c)
	a - OK
	ab - OK
	abc - OK
	b - NO
	c - NO
	And so on...
	
Writes: Indexes actually slows down your writes... Writes are much faster when there is no index
Read: But READS will be much faster!

Which optimization will typically have the greatest impact on the performance of a database?
A: Adding appropriate indexes on large collections so that only a small percentage of queries need to scan the collection.

// --------- Creating indexes

Use create_scores2.6f9f5645026a.js file to create 1.000.000 documents.
> db.students.find({ student_id: 5 }) // It will take a bunch of time
> db.students.explain().find({ student_id: 5 })
// On winningPlan you can see which type of scan was used during the query. For our case is COLLSCAN, it means that the collection was fully scanned (all the documents) in order to retrieve what was asked.
> db.students.findOne({ student_id: 5 }) // Faster than the find() option
> db.students.createIndex({ student_id: 1 }) // We want to create index on student_id ascending
> db.students.explain().find({ student_id: 5 })
> db.students.explain(true).find({ student_id: 5 }) // You can see how much documents were used in order to retrieve what was asked
> db.students.createIndex({ student_id: 1, class_id: -1 }) // student_id ascending and class_id descending

// --------- Discovering and Deleting Indexes

> db.students.getIndexes(); // There is default index which is on _id and you can't delete it
> db.students.dropIndexex({ student_id: 1 })

// --------- Multikey Indexes

Creating indexes on arrays is known as "multikey indexes".

{
	name : 'Budega',
	tags : [ 'tennis', 'programming', 'music' ],
	color : 'blue',
	location : ['SP', 'RJ']
}

Legal indexes: (tags), (tags, color)
Illegal indexes: (tags, location) -> Multikey indexes doesn't allow compound index to have two arrays

> db.foo.insert({ a : 1, b: 2 })
> db.foo.find()
> db.foo.createIndex({ a : 1, b : 1 })
> db.foo.explain().find({ a : 1, b : 1 }) // See indexName and isMultiKey fields
> db.foo.insert({ a : 3, b: [3,5,7] })
> db.foo.explain().find({ a : 1, b : 1 }) // See isMultiKey equals true now
> db.foo.explain().find({ a : 1, b : 5 })
> db.foo.getIndexes();
> db.foo.insert({ a : [3,4,6], b: [7,8,9] }) // It won't work: cannot index parallel arrays [b] [a]
> db.foo.insert({ a : [3,4,6], b: 8 }) // It works because it doesn't have parallel arrays

// --------- Dot notation and multikey

https://docs.mongodb.com/manual/reference/operator/query/elemMatch/

> db.students.createIndex({ 'scores.score' : 1 })
> db.students.explain().find({ 'scores.score' : { '$gt' : 99 } })
> db.students.find({ 'scores' : { '$elemMatch' : { type : 'exam', score : { '$gt' : 99.8 } } } }).count()
> db.students.explain().find({ 'scores' : { '$elemMatch' : { type : 'exam', score : { '$gt' : 99.8 } } } }) // You can see that the index search is made and then elemMatch ran in each document which were retrieved
> db.students.explain(true).find({ 'scores' : { '$elemMatch' : { type : 'exam', score : { '$gt' : 99.8 } } } }) // Just to make sure that the above statement is true... See docsExamined field.
> db.students.find({ 'scores.score' : { '$gt' : 99.8 } }).count() // It must matched docsExamined above
> db.students.find({ '$and' : [{ 'scores.type' : 'exam' }, { 'scores.score' : { '$gt' : 99.8 } }] }) // It does not work as elemMatch as you may get documents which you didn't want to
> db.students.explain().find({ '$and' : [{ 'scores.type' : 'exam' }, { 'scores.score' : { '$gt' : 99.8 } }] })

Suppose you have a collection called people in the database earth with documents of the following form:

{
    "_id" : ObjectId("551458821b87e1799edbebc4"),
    "name" : "Eliot Horowitz",
    "work_history" : [
        {
            "company" : "DoubleClick",
            "position" : "Software Engineer"
        },
        {
            "company" : "ShopWiki",
            "position" : "Founder & CTO"
        },
        {
            "company" : "MongoDB",
            "position" : "Founder & CTO"
        }
    ]
}

Type the command that you would issue in the Mongo shell to create an index on company, descending.

> db.people.createIndex({ 'work_history.company' : -1 })


// --------- Index Creation Options, Unique

https://docs.mongodb.com/v3.0/reference/method/db.collection.createIndex/#options

> db.stuff.drop();
> db.stuff.insert({ 'thing' : 'apple' })
> db.stuff.insert({ 'thing' : 'pear' })
> db.stuff.insert({ 'thing' : 'apple' })
> db.stuff.find()
> db.stuff.createIndex({ 'thing' : 1 })
> db.stuff.dropIndex({ 'thing' : 1 }, { unique: true }) // Error because there are two apples
> db.stuff.remove({ 'thing' : 'apple' }, { justOne: true })
> db.stuff.dropIndex({ 'thing' : 1 }, { unique: true }) // It works
> db.stuff.insert({ 'thing' : 'pear' }) // Duplicate key error
> db.stuff.getIndexes()

Please provide the mongo shell command to create a unique index on student_id, class_id, ascending for the collection students.
> db.students.createIndex({ student_id: 1, class_id: 1 }, { unique : true })

// --------- Sparse Indexes

https://docs.mongodb.com/manual/indexes/#sparse-indexes

It's a sort of index that can be used when the index key is missing from some of documents.
When you specify this options you tells MongoDB that it should not include in the index documents that are missing the key.

> db.employees.createIndex({ cell: 1}, { unique : true, sparse, true } })

One advantage of using sparse index is that it uses a lot less space than the common one.

What are the advantages of a sparse index?
A: The index will be smaller than it would if it were not sparse; You can gain greater flexibility with creating Unique indexes.

// --------- Index creation, background

http://docs.mongodb.org/manual/core/index-creation/?_ga=2.144413107.721559069.1498430831-1068873678.1493258930#index-creation-background

• Foreground
	1 - Fast
	2 - Blocks writers and readers in the database, it means... DO NOT DO IT IN PRODUCTION SYSTEMS!
• Background
	1 - Slower
	2 - DON'T block writers and readers in the database, it means... DO NOT DO IT IN PRODUCTION SYSTEMS!
	
> db.students.createIndex({ 'score.score' : 1 }, { background : true })

Which things are true about creating an index in the background in MongoDB.
A: Although the database server will continue to take requests, a background index creation still blocks the mongo shell that you are using to create the index; Creating an index in the background takes longer than creating it in the foreground.

Note that, in MongoDB 2.2, the answer that you can only make one background index per database would have been correct.

// --------- Using explain

https://docs.mongodb.com/manual/reference/explain-results/

Explain is used to find out what the database is doing with your query, how it's executing it, what indexes it's using and how many documents it inspected when it actually runs the query. It didn't bring data to the client, only the "explain" information.

> var exp = db.foo.explain()
> exp.help()

// --------- Explain: verbosity

Explain runs using "query planner" mode by default and we're using it like that so far. There are two other modes:
	0 - Query planner: Standard one. It tells you mostly what the database would use in terms of the indexes
	1 - Execution stats: It includes query planner and it tells the results of the query like number of documents returned, how much time it will take to accomplish the query and so on.
	2 - All plans execution: It includes query planner and execution stats. When you run using this option actually you're running the query optimizer that periodically runs to determine what index would be used for any particular shape of query.
> var exp = db.example.explain("executionStats")
> exp.find({ a : 17, b : 55 })
> db.example.dropIndex({ a : 1, b : 1 })
> exp.find({ a : 17, b : 55 })
> db.example.createIndex({ a : 1, b : 1 })
> var exp = db.example.explain("allPlansExecution")
> exp.find({ a : 17, b : 55 })

Given the following output from explain, what is the best description of what happened during the query?

> exp = db.example.explain("executionStats")
Explainable(test.example)
> exp.find( { a : 7 } )
{
    "queryPlanner" : {
        "plannerVersion" : 1,
        "namespace" : "test.example",
        "indexFilterSet" : false,
        "parsedQuery" : {
            "a" : {
                "$eq" : 7
            }
        },
        "winningPlan" : {
            "stage" : "COLLSCAN",
            "filter" : {
                "a" : {
                    "$eq" : 7
                }
            },
            "direction" : "forward"
        },
        "rejectedPlans" : [ ]
    },
    "executionStats" : {
        "executionSuccess" : true,
        "nReturned" : 10000,
        "executionTimeMillis" : 619,
        "totalKeysExamined" : 0,
        "totalDocsExamined" : 999999,
        "executionStages" : {
            "stage" : "COLLSCAN",
            "filter" : {
                "a" : {
                    "$eq" : 7
                }
            },
            "nReturned" : 10000,
            "executionTimeMillisEstimate" : 520,
            "works" : 1000001,
            "advanced" : 10000,
            "needTime" : 990000,
            "needFetch" : 0,
            "saveState" : 7812,
            "restoreState" : 7812,
            "isEOF" : 1,
            "invalidates" : 0,
            "direction" : "forward",
            "docsExamined" : 999999
        }
    },
    "serverInfo" : {
        "host" : "cross-mb-air.local",
        "port" : 27017,
        "version" : "3.0.1",
        "gitVersion" : "534b5a3f9d10f00cd27737fbcd951032248b5952"
    },
    "ok" : 1
}

A: The query scanned 999,999 documents, returning 10,000 in 619 milliseconds.

// --------- Covered Queries

https://www.tutorialspoint.com/mongodb/mongodb_covered_queries.htm
https://docs.mongodb.com/manual/core/query-optimization/#covered-query

A covered query is a query that can be satisfied entirely using an index and does not have to examine any documents.	

You would like to perform a covered query on the example collection. You have the following indexes:

{ name : 1, dob : 1 }
{ _id : 1 }
{ hair : 1, name : 1 }

Which of the following is likely to be a covered query?
A: db.example.find( { name : { $in : [ "Bart", "Homer" ] } }, {_id : 0, dob : 1, name : 1} )

// --------- When is an index used?

We no longer evict plans from the cache after a threshold number of writes. Instead, we evict when the "works" of the first portion of the query exceed the number of "works" used to decide on the winning plan by a factor of 10x. You can see the "works" for a particular plan using .explain("executionStats").

Let's suppose we have the following indexes:
	1 - b,c
	2 - c,d
	3 - d,e
	4 - e,f
	5 - a,b,c
When we issue a query where it may use index 1, 2 or 5, MongoDB will then create three query plans. In three parallel threads issue the query such that each one will use a different index and see which one is able to return results the fastest.

The WINNING QUERY PLAN in stored in a CACHE for future use for queries of that shape. The cache is erased using one of the following:
1 - Threshold (number of writes)
2 - Rebuild the index
3 - Any index is added or dropped from the collection
4 - mongod proccess is restarted

Given collection foo with the following index:

db.foo.createIndex( { a : 1, b : 1, c : 1 } )

Which of the following queries will use the index?
A. db.foo.find( { a : 3 } )
A. db.foo.find( { c : 1 } ).sort( { a : 1, b : 1 } )

// --------- How large is your index?

Working set: It's the portion of data that clients are frequently accessing and is located in memory. The key of it is the index, so it's important that our indexes fit into memory.

db.students.stats();
db.students.totalIndexSize();

Wired tiger storage engine may use prefix compression to thinner indexes when compared with MMAP.

// --------- Number of index entries

https://docs.mongodb.com/manual/reference/method/cursor.showRecordId/?_ga=2.126767821.1114842536.1499002021-1068873678.1493258930#cursor.showRecordId

In this lecture, we talk about the cost of moving documents, in terms of updating index entries. That cost only exists in the MMAPv1 storage engine. In the WiredTiger storage engine, index entries don't contain pointers to actual disk locations. Instead, in WiredTiger, the index points to an internal document identifier (the RecordId) that is immutable. Therefore, when a document is updated, its index does not need to be updated at all.

Index cardinality: How many index points are there for each different type of index that MongoDB supports:
	1 - Regular: For every single key that you put in the index, there's certainly going to be an index point. And in addition, if there is no key, then there's going to be an index point under the null entry ----> 1:1
	2 - Sparse: When a document is missing the key being indexed, it's not in the index because it's a null and we don't keep nulls in the index for a sparse index. ----> <= number of documents
	3 - Multikey: It's a index on an array value. Then there may be multiple index points for each document. For example... If there is a tag which has 4 elements, then there's going to be an index point for every single one these keys/elements ----> > number of documents

Let's say you update a document with a key called tags and that update causes the document to need to get moved on disk. Assume you are using the MMAPv1 storage engine. If the document has 100 tags in it, and if the tags array is indexed with a multikey index, how many index points need to be updated in the index to accommodate the move? Put just the number below.
A. 100	

// --------- Geospatial indexes

Obs.: This lecture uses the now deprecated ensureIndex shell command. The preferred command is createIndex. Anywhere you see me using ensureIndex imagine I used createIndex.

Geospatial indexes allow us to find things based on location (it can be any field, but must match its shape).

https://docs.mongodb.com/manual/reference/operator/query-geospatial/

'location' : [x, y]
createIndex({ 'location' : '2d', 'type': 1 }) // 2d tells the database that this is a two-dimensional geospatial index
find({ 'location' : { $near : [x, y] }}).limit(20) // Sample: all the shops that were closest to this "person" standing at coordinates x and y limiting to 20 of them.

Suppose you have a 2D geospatial index defined on the key location in the collection places. Write a query that will find the closest three places (the closest three documents) to the location 74, 140.
A. db.places.find({ 'location' : { $near : [74, 140] }}).limit(3)

// --------- Geospatial spherical

2dsphere is a type of index for it.
MongoDB uses a location specification called GeoJSON.

db.places.createIndex({ 'location' : '2dsphere'})
db.places.getIndexes()
db.places.find({
	location : {
		$near : {
			$geometry : {
				type : "Point",
				coordinates : [-122.166641, 37.4278925]
			},
			$maxDistance : 2000
		}
	}	
})

What is the query that will query a collection named "stores" to return the stores that are within 1,000,000 meters of the location latitude=39, longitude=-130? Type the query in the box below. Assume the stores collection has a 2dsphere index on "loc" and please use the "$near" operator. Each store record looks like this:

{
    "_id":{
        "$oid":"535471aaf28b4d8ee1e1c86f"
    },
    "store_id":8,
    "loc":{
        "type":"Point",
        "coordinates":[
            -37.47891236119904,
            4.488667018711567
        ]
    }
}

A. db.stores.find({ 'loc' : { $near : { $geometry : { 'type' : 'Point', 'coordinates' : [-130,39]}, $maxDistance : 1000000}}})

// --------- Text indexes

Full text search index...

https://docs.mongodb.com/manual/core/index-text/
https://docs.mongodb.com/manual/reference/operator/query/text/

db.sentences.createIndex({ 'words' : 'text' }) // it enables full text search
db.senteces.find({ $text : { $search : 'dog' }})

https://docs.mongodb.com/manual/reference/operator/aggregation/meta/#exp._S_meta

db.senteces.find({ $text : { $search : 'dog' }}, { 'score' : { $meta : 'textScore' }}).sort({ 'score' : { $meta : 'textScore'}})

// -- Quiz

You create a text index on the "title" field of the movies collection, and then perform the following text search:

> db.movies.find( { $text : { $search : "Big Lebowski" } } )

Which of the following documents will be returned, assuming they are in the movies collection? Check all that apply.
A. { "title" : "The Big Lebowski" , star: "Jeff Bridges" }
A. { "title" : "Big" , star : "Tom Hanks" }
A. { "title" : "Big Fish" , star: "Ewan McGregor" }

// --------- Efficiency of Index Use / Designing/Using Indexes

Main goal: Efficient read/write operations
One good way to achieve it is to test your indexes under some real world workloads and make adjustments from there.
Key goals:
	- Selectivity - Minimize records scanned

https://docs.mongodb.com/manual/reference/method/cursor.hint/	

db.students.find({student_id:{$gt:500000}, class_id:54}).sort({student_id:1}).hint({class_id:1}).explain("executionstats")

// -- Quiz

1 - In general, based on the preceding lecture, what is the primary factor that determines how efficiently an index can be used?
A. The selectivity of the index.
WHY: Selectivity is the primary factor that determines how efficiently an index can be used. Ideally, the index enables us to select only those records required to complete the result set, without the need to scan a substantially larger number of index keys (or documents) in order to complete the query. Selectivity determines how many records any subsequent operations must work with. Fewer records means less execution time.

2 - In general, which of the following rules of thumb should you keep in mind when building compound indexes? Check all that apply. For this question, use the following definitions:

equality field: field on which queries will perform an equality test
sort field: field on which queries will specify a sort
range field: field on which queries perform a range test

A. Equality fields before range fields
A. Sort fields before range fields
A. Equality fields before sort fields

// --------- Logging slow queries

https://docs.mongodb.com/manual/tutorial/manage-the-database-profiler/#profiling-levels

MongoDB automatically logs slows queries of above 100 milliseconds right to the log.

// --------- Profiling

https://docs.mongodb.com/manual/reference/database-profiler/

There are THREE levels for the profiler.
	Level 0: Standard level and by default it is off.
	Level 1: It logs all slow queries which are above 100 milliseconds.
	Level 2: It logs all queries with no constraint --> Used during development general known as debugging feature.
> mongod -dppath /usr/local/var/mongodb --profile 1 --slowms 2
> db.students.find({ 'student_id' : 10000 })
> db.system.profile.find().pretty()
// Find anything which name space (ns) matches students collection and sort by timestamp (ts)
> db.system.profile.find({ ns : /school.students/ }).sort({ ts : 1 })pretty() 
> db.system.profile.find({ millis : { $gt : 1 }}).sort({ ts : 1 })pretty() 

> db.getProfilingLevel()
> db.getProfilingStatus()
// Set profiling level to 1 and log queries which take 4 milliseconds to execute
> db.setProfilingLevel(1, 4)
// Turn everything off
> db.setProfilingLevel(0)

// -- Quiz

Write the query to look in the system profile collection for all queries that took longer than one second, ordered by timestamp descending.

A. db.system.profile.find({ millis : { $gt : 1000 }}).sort({ ts : -1 })

// --------- mongotop

https://docs.mongodb.com/manual/reference/program/mongotop/

Mongotop is named after the Unix Top command. It gives a high level view of where Mongo is spending its time.

// --------- mongostat

https://docs.mongodb.com/manual/reference/program/mongostat/

Mongostat is a performance tuning command and is pretty similar to iostat command from the Unix world.

// -- Quiz

Which of the following statements about mongostat output are true?
A. The getmore column concerns the number of requests per time interval to get additional data from a cursor
A. The faults column appears only in the mmapv1 output

// --------- Sharding

https://docs.mongodb.com/manual/sharding/

Sharding is a technique for splitting up a large collection amongst multiple servers.
Replica set keeps the data in sync across several different instances.

##### Homework 4.1

Suppose you have a collection with the following indexes:

> db.products.getIndexes()
[
    {
        "v" : 1,
        "key" : {
            "_id" : 1
        },
        "ns" : "store.products",
        "name" : "_id_"
    },
    {
        "v" : 1,
        "key" : {
            "sku" : 1
        },
                "unique" : true,
        "ns" : "store.products",
        "name" : "sku_1"
    },
    {
        "v" : 1,
        "key" : {
            "price" : -1
        },
        "ns" : "store.products",
        "name" : "price_-1"
    },
    {
        "v" : 1,
        "key" : {
            "description" : 1
        },
        "ns" : "store.products",
        "name" : "description_1"
    },
    {
        "v" : 1,
        "key" : {
            "category" : 1,
            "brand" : 1
        },
        "ns" : "store.products",
        "name" : "category_1_brand_1"
    },
    {
        "v" : 1,
        "key" : {
            "reviews.author" : 1
        },
        "ns" : "store.products",
        "name" : "reviews.author_1"
    }
]

Which of the following queries can utilize at least one index to find all matching documents, or to sort? Check all that apply.

Note: the text for some answers may wrap; you can ignore the wrapping.

A. db.products.find( { 'brand' : "GE" } ).sort( { price : 1 } )
A. db.products.find( { $and : [ { price : { $gt : 30 } }, { price : { $lt : 50 } } ] } ).sort( { brand : 1 } )

##### Homework 4.2

Suppose you have a collection called tweets whose documents contain information about the created_at time of the tweet and the user's followers_count at the time they issued the tweet. What can you infer from the following explain output?

> db.tweets.explain("executionStats").find( { "user.followers_count" : { $gt : 1000 } } ).limit(10).skip(5000).sort( { created_at : 1 } )
{
    "queryPlanner" : {
        "plannerVersion" : 1,
        "namespace" : "twitter.tweets",
        "indexFilterSet" : false,
        "parsedQuery" : {
            "user.followers_count" : {
                "$gt" : 1000
            }
        },
        "winningPlan" : {
            "stage" : "LIMIT",
            "limitAmount" : 0,
            "inputStage" : {
                "stage" : "SKIP",
                "skipAmount" : 0,
                "inputStage" : {
                    "stage" : "FETCH",
                    "filter" : {
                        "user.followers_count" : {
                            "$gt" : 1000
                        }
                    },
                    "inputStage" : {
                        "stage" : "IXSCAN",
                        "keyPattern" : {
                            "created_at" : -1
                        },
                        "indexName" : "created_at_-1",
                        "isMultiKey" : false,
                        "direction" : "backward",
                        "indexBounds" : {
                            "created_at" : [
                                "[MinKey, MaxKey]"
                            ]
                        }
                    }
                }
            }
        },
        "rejectedPlans" : [ ]
    },
    "executionStats" : {
        "executionSuccess" : true,
        "nReturned" : 10,
        "executionTimeMillis" : 563,
        "totalKeysExamined" : 251120,
        "totalDocsExamined" : 251120,
        "executionStages" : {
            "stage" : "LIMIT",
            "nReturned" : 10,
            "executionTimeMillisEstimate" : 500,
            "works" : 251121,
            "advanced" : 10,
            "needTime" : 251110,
            "needFetch" : 0,
            "saveState" : 1961,
            "restoreState" : 1961,
            "isEOF" : 1,
            "invalidates" : 0,
            "limitAmount" : 0,
            "inputStage" : {
                "stage" : "SKIP",
                "nReturned" : 10,
                "executionTimeMillisEstimate" : 500,
                "works" : 251120,
                "advanced" : 10,
                "needTime" : 251110,
                "needFetch" : 0,
                "saveState" : 1961,
                "restoreState" : 1961,
                "isEOF" : 0,
                "invalidates" : 0,
                "skipAmount" : 0,
                "inputStage" : {
                    "stage" : "FETCH",
                    "filter" : {
                        "user.followers_count" : {
                            "$gt" : 1000
                        }
                    },
                    "nReturned" : 5010,
                    "executionTimeMillisEstimate" : 490,
                    "works" : 251120,
                    "advanced" : 5010,
                    "needTime" : 246110,
                    "needFetch" : 0,
                    "saveState" : 1961,
                    "restoreState" : 1961,
                    "isEOF" : 0,
                    "invalidates" : 0,
                    "docsExamined" : 251120,
                    "alreadyHasObj" : 0,
                    "inputStage" : {
                        "stage" : "IXSCAN",
                        "nReturned" : 251120,
                        "executionTimeMillisEstimate" : 100,
                        "works" : 251120,
                        "advanced" : 251120,
                        "needTime" : 0,
                        "needFetch" : 0,
                        "saveState" : 1961,
                        "restoreState" : 1961,
                        "isEOF" : 0,
                        "invalidates" : 0,
                        "keyPattern" : {
                            "created_at" : -1
                        },
                        "indexName" : "created_at_-1",
                        "isMultiKey" : false,
                        "direction" : "backward",
                        "indexBounds" : {
                            "created_at" : [
                                "[MinKey, MaxKey]"
                            ]
                        },
                        "keysExamined" : 251120,
                        "dupsTested" : 0,
                        "dupsDropped" : 0,
                        "seenInvalidated" : 0,
                        "matchTested" : 0
                    }
                }
            }
        }
    },
    "serverInfo" : {
        "host" : "generic-name.local",
        "port" : 27017,
        "version" : "3.0.1",
        "gitVersion" : "534b5a3f9d10f00cd27737fbcd951032248b5952"
    },
    "ok" : 1
}

A. The query uses an index to determine the order in which to return result documents.
A. The query examines 251120 documents.

##### Homework 4.3

> use blog;
> db.posts.drop();
// I have to broke it in three parts because of the maximum size of the file (16 MB)
> mongoimport -d blog -c posts < posts0.json
> mongoimport -d blog -c posts < posts1.json
> mongoimport -d blog -c posts < posts2.json
// Homepage
> db.posts.createIndex({ 'date' : -1 })
// Permalink page
db.posts.createIndex({ 'permalink' : 1 })
// Using unique is probably better and matches the blog rules
db.posts.createIndex({ 'permalink' : 1 }, { 'unique' : true })
// All the posts from a particular tag and order them by date
db.posts.createIndex({ 'tags' : 1, 'date' : -1 })

##### Homework 4.4

> mongoimport --drop -d m101 -c sysprofile sysprofile.json

Now query the profile data, looking for all queries to the students collection in the database school2, sorted in order of decreasing latency. What is the latency of the longest running operation to the collection, in milliseconds?

> db.profile.find({ns: "school2.students" }, {_id: 0, millis: 1 } ).sort( { millis: -1 } ).limit(3)
{ "millis" : 15820 }
{ "millis" : 12560 }
{ "millis" : 11084 }

A. 15820

########################################
########## WEEK 5 - AGGREGATION FRAMEWORK
#### TOPICS: Goals, The Use Of The Pipeline, Comparison With SQL Facilities.

// --------- Simple aggregation example

https://docs.mongodb.com/manual/reference/method/db.collection.aggregate/

> use agg
> db.products.drop()
> db.products.insertMany([{'name':'iPad 16GB Wifi', 'manufacturer':"Apple", 'category':'Tablets', 'price':499.00},
{'name':'iPad 32GB Wifi', 'category':'Tablets', 'manufacturer':"Apple", 'price':599.00},
{'name':'iPad 64GB Wifi', 'category':'Tablets', 'manufacturer':"Apple", 'price':699.00},
{'name':'Galaxy S3', 'category':'Cell Phones', 'manufacturer':'Samsung','price':563.99},
{'name':'Galaxy Tab 10', 'category':'Tablets', 'manufacturer':'Samsung','price':450.99},
{'name':'Vaio', 'category':'Laptops', 'manufacturer':"Sony", 'price':499.00},
{'name':'Macbook Air 13inch', 'category':'Laptops', 'manufacturer':"Apple", 'price':499.00},
{'name':'Nexus 7', 'category':'Tablets', 'manufacturer':"Google", 'price':199.00},
{'name':'Kindle Paper White', 'category':'Tablets', 'manufacturer':"Amazon", 'price':129.00},
{'name':'Kindle Fire', 'category':'Tablets', 'manufacturer':"Amazon", 'price':199.00}])

// SAMPLE SQL WORLD
> SELECT Manufacturer, COUNT(*) FROM Products GROUP BY Manufacturer;
// NOSQL WORLD
> db.products.aggregate([
	{
		$group : {
			_id : "$manufacturer",
			num_products : { $sum : 1 }
		}
	}
])
// RESULT OF THE AGGREGATE ABOVE:
{ "_id" : "Amazon", "num_products" : 2 }
{ "_id" : "Apple", "num_products" : 4 }
{ "_id" : "Samsung", "num_products" : 2 }
{ "_id" : "Sony", "num_products" : 1 }
{ "_id" : "Google", "num_products" : 1 }

// -- Quiz

Write the aggregation query that will find the number of products by category of a collection that has the form:

{
    "_id" : ObjectId("50b1aa983b3d0043b51b2c52"),
    "name" : "Nexus 7",
    "category" : "Tablets",
    "manufacturer" : "Google",
    "price" : 199
}

Have the resulting key be called "num_products," as in the video lesson. Hint, you just need to change which key you are aggregating on relative to the examples shown in the lesson.

Please double quote all keys to make it easier to check your result.

db.products.aggregate([
	{
		$group : {
			_id : "$category",
			num_products : { $sum : 1 }
		}
	}
])

// --------- Aggregation pipeline

https://docs.mongodb.com/manual/core/aggregation-pipeline/
https://docs.mongodb.com/manual/reference/operator/aggregation/#aggregation-pipeline-operator-reference

Which of the following are stages in the aggregation pipeline. Check all that apply.

A. Match, Group, Skip, Limit, Sort, Project and Unwind.

// --------- Simple aggregation example

// -- Quiz

If you have the following collection of stuff:

> db.stuff.find()
{ "_id" : ObjectId("50b26f9d80a78af03b5163c8"), "a" : 1, "b" : 1, "c" : 1 }
{ "_id" : ObjectId("50b26fb480a78af03b5163c9"), "a" : 2, "b" : 2, "c" : 1 }
{ "_id" : ObjectId("50b26fbf80a78af03b5163ca"), "a" : 3, "b" : 3, "c" : 1 }
{ "_id" : ObjectId("50b26fcd80a78af03b5163cb"), "a" : 3, "b" : 3, "c" : 2 }
{ "_id" : ObjectId("50b26fd380a78af03b5163cc"), "a" : 3, "b" : 5, "c" : 3 }

and you perform the following aggregation:

> db.stuff.aggregate([{$group:{_id:'$c'}}])

How many documents will be in the result set from aggregate?
A. 3


// --------- Compound groupings

Let's suppose we want to find out the number of products that each manufacturer had in each category?

// SAMPLE SQL WORLD
> SELECT manufacturer, category, COUNT(*) FROM products GROUP BY manufacturer, category;
// NOSQL WORLD
> db.products.aggregate([
    {
		$group: {
			_id: { "manufacturer" : "$manufacturer", "category" : "$category"},
			num_products : { $sum : 1 }
		}
    }
])
// RESULT OF THE AGGREGATE ABOVE:
{ "_id" : { "manufacturer" : "Google", "category" : "Tablets" }, "num_products" : 1 }
{ "_id" : { "manufacturer" : "Sony", "category" : "Laptops" }, "num_products" : 1 }
{ "_id" : { "manufacturer" : "Apple", "category" : "Tablets" }, "num_products" : 3 }
{ "_id" : { "manufacturer" : "Samsung", "category" : "Cell Phones" }, "num_products" : 1 }
{ "_id" : { "manufacturer" : "Samsung", "category" : "Tablets" }, "num_products" : 1 }
{ "_id" : { "manufacturer" : "Apple", "category" : "Laptops" }, "num_products" : 1 }
{ "_id" : { "manufacturer" : "Amazon", "category" : "Tablets" }, "num_products" : 2 }

// -- Quiz

Given the following collection:

> db.stuff.find()
{ "_id" : ObjectId("50b26f9d80a78af03b5163c8"), "a" : 1, "b" : 1, "c" : 1 }
{ "_id" : ObjectId("50b26fb480a78af03b5163c9"), "a" : 2, "b" : 2, "c" : 1 }
{ "_id" : ObjectId("50b26fbf80a78af03b5163ca"), "a" : 3, "b" : 3, "c" : 1 }
{ "_id" : ObjectId("50b26fcd80a78af03b5163cb"), "a" : 3, "b" : 3, "c" : 2 }
{ "_id" : ObjectId("50b26fd380a78af03b5163cc"), "a" : 3, "b" : 5, "c" : 3 }
{ "_id" : ObjectId("50b27f7080a78af03b5163cd"), "a" : 3, "b" : 3, "c" : 2 }

And the following aggregation query:

db.stuff.aggregate([
	{
		$group: {
			_id: {'moe':'$a', 'larry':'$b', 'curly':'$c'}
		}
	}
])

How many documents will be in the result set?
A. 5

// --------- Aggregation expressions overview

$sum, $avg, $min, $max, $push, $addToSet, $fisrt, $last ---> For $group stage
$push, $addToSet -> Build arrays.
$fisrt, $last -> Require first to sort the documents or they don't make any sense.

// --------- Using $sum

// -- Quiz

mongoimport -d week5 -c zips < zips.f7b79f61a996.json

Suppose we have a collection of populations by postal code. The postal codes in are in the _id field, and are therefore unique. Documents look like this:

{
    "city" : "CLANTON",
    "loc" : [
        -86.642472,
        32.835532
    ],
    "pop" : 13990,
    "state" : "AL",
    "_id" : "35045"
}

Write an aggregation query to sum up the population (pop) by state and put the result in a field called population. Don't use a compound _id key (you don't need one and the quiz checker is not expecting one). The collection name is zips. so something along the lines of db.zips.aggregate...

A. > db.zips.aggregate([
	{
		$group : {
			_id : "$state",
			population : { $sum : "$pop" }
		}
	}
])

// --------- Using $avg

// -- Quiz

Given population data by zip code (postal code) that looks like this:

{
    "city" : "FISHERS ISLAND",
    "loc" : [
            -72.017834,
            41.263934
    ],
    "pop" : 329,
    "state" : "NY",
    "_id" : "06390"
}

Write an aggregation expression to calculate the average population of a zip code (postal code) by state. As before, the postal code is in the _id field and is unique. The collection is assumped to be called "zips" and you should name the key in the result set "average_pop"

A. > db.zips.aggregate([
	{
		$group : {
			_id : "$state",
			average_pop : { $avg : "$pop" }
		}
	}
])

// --------- Using $addToSet

// -- Quiz

Suppose we population by zip code (postal code) data that looks like this (putting in a query for the zip codes in Palo Alto)

> db.zips.find({state:"CA",city:"PALO ALTO"})
{ "city" : "PALO ALTO", "loc" : [ -122.149685, 37.444324 ], "pop" : 15965, "state" : "CA", "_id" : "94301" }
{ "city" : "PALO ALTO", "loc" : [ -122.184234, 37.433424 ], "pop" : 1835, "state" : "CA", "_id" : "94304" }
{ "city" : "PALO ALTO", "loc" : [ -122.127375, 37.418009 ], "pop" : 24309, "state" : "CA", "_id" : "94306" }

Write an aggregation query that will return the postal codes that cover each city. The results should look like this:

{
    "_id" : "CENTREVILLE",
    "postal_codes" : [
        "22020",
        "49032",
        "39631",
        "21617",
        "35042"
    ]
},

Again the collection will be called zips. You can deduce what your result column names should be from the above output. (ignore the issue that a city may have the same name in two different states and is in fact two different cities in that case - for eg Springfield, MO and Springfield, MA)

A. > db.zips.aggregate([
	{
		$group : {
			_id : "$city",
			postal_codes : { $addToSet : "$_id" }
		}
	}
])

// --------- Using $push

// -- Quiz

Given the zipcode dataset (explained more fully in the using $sum quiz) that has documents that look like this:

> db.zips.findOne()
{
    "city" : "ACMAR",
    "loc" : [
        -86.51557,
        33.584132
    ],
    "pop" : 6055,
    "state" : "AL",
    "_id" : "35004"
}

would you expect the following two queries to produce the same result or different results?

db.zips.aggregate([{"$group":{"_id":"$city", "postal_codes":{"$push":"$_id"}}}])
db.zips.aggregate([{"$group":{"_id":"$city", "postal_codes":{"$addToSet":"$_id"}}}])

A. SAME because _id field is unique, thus doesn't matter if you use push or addToSet, the result will be the same.

// --------- Using $max and $min

// -- Quiz

Again thinking about the zip code database, write an aggregation query that will return the population of the postal code in each state with the highest population. It should return output that looks like this:

{
	"_id" : "WI",
	"pop" : 57187
},
{
	"_id" : "WV",
	"pop" : 70185
},
..and so on

A. > db.zips.aggregate([
	{
		$group : {
			_id : "$state",
			pop : { $max : "$pop" }
		}
	}
])

// --------- Double $group stages

// -- Quiz

Given the following collection:

> db.fun.find()
{ "_id" : 0, "a" : 0, "b" : 0, "c" : 21 }
{ "_id" : 1, "a" : 0, "b" : 0, "c" : 54 }
{ "_id" : 2, "a" : 0, "b" : 1, "c" : 52 }
{ "_id" : 3, "a" : 0, "b" : 1, "c" : 17 }
{ "_id" : 4, "a" : 1, "b" : 0, "c" : 22 }
{ "_id" : 5, "a" : 1, "b" : 0, "c" : 5 }
{ "_id" : 6, "a" : 1, "b" : 1, "c" : 87 }
{ "_id" : 7, "a" : 1, "b" : 1, "c" : 97 }

And the following aggregation query:

db.fun.aggregate([
	{
		$group : {
			_id : {a:"$a", b:"$b"}, 
			c : {$max:"$c"}
		}
	}, 
	{
		$group : {
			_id : "$_id.a", 
			c : { $min:"$c" }
		}
	}
])

What values are returned?

A. db.fun.insertMany([{ "_id" : 0, "a" : 0, "b" : 0, "c" : 21 },
{ "_id" : 1, "a" : 0, "b" : 0, "c" : 54 },
{ "_id" : 2, "a" : 0, "b" : 1, "c" : 52 },
{ "_id" : 3, "a" : 0, "b" : 1, "c" : 17 },
{ "_id" : 4, "a" : 1, "b" : 0, "c" : 22 },
{ "_id" : 5, "a" : 1, "b" : 0, "c" : 5 },
{ "_id" : 6, "a" : 1, "b" : 1, "c" : 87 },
{ "_id" : 7, "a" : 1, "b" : 1, "c" : 97 }])

When the aggregation query run it returns:
{ "_id" : 0, "c" : 52 }
{ "_id" : 1, "c" : 22 }

// --------- Using $project

The project phase lets you reshape the documents as they come through the pipeline.

// -- Quiz

Write an aggregation query with a single projection stage that will transform the documents in the zips collection from this:

{
    "city" : "ACMAR",
    "loc" : [
        -86.51557,
        33.584132
    ],
    "pop" : 6055,
    "state" : "AL",
    "_id" : "35004"
}

to documents in the result set that look like this:

{
    "city" : "acmar",
    "pop" : 6055,
    "state" : "AL",
    "zip" : "35004"
}

So that the checker works properly, please specify what you want to do with the _id key as the first item. The other items should be ordered as above. As before, assume the collection is called zips. You are running only the projection part of the pipeline for this quiz.

Obs.: If you want to include a key exactly as it is named in the source document, you just write key:1, where key is the name of the key.

A. > db.zips.aggregate([
	{
		$project : {
			_id : 0,
			city : { $toLower: "$city" },
			pop : 1,
			state : 1,
			zip : "$_id"
		}
	}
])

// --------- Using $match

// -- Quiz

Again, thinking about the zipcode collection, write an aggregation query with a single match phase that filters for zipcodes with greater than 100,000 people. You may need to look up the use of the $gt operator in the MongoDB docs. Assume the collection is called zips.

A. > db.zips.aggregate([
	{
		$match : {
			pop : { $gt : 100000 }
		}
	}
])

// --------- Using $sort

// -- Quiz

Again, considering the zipcode collection, which has documents that look like this,

{
    "city" : "ACMAR",
    "loc" : [
        -86.51557,
        33.584132
    ],
    "pop" : 6055,
    "state" : "AL",
    "_id" : "35004"
}

Write an aggregation query with just a sort stage to sort by (state, city), both ascending. Assume the collection is called zips.

A. > db.zips.aggregate([
	{
		$sort : {
			state: 1,
			city: 1
		}
	}
])

// --------- Using $limit and $skip

// -- Quiz

Suppose you change the order of skip and limit in the query shown in the lesson, to look like this:

db.zips.aggregate([
    { $match: { state:"NY" } },
    { $group: { _id: "$city", population: {$sum:"$pop"}} },
    { $project: { _id: 0, city: "$_id", population: 1} },
    { $sort: { population:-1 } },
    {$limit: 5},
    {$skip: 10}
])

How many documents do you think will be in the result set?

A. 0

// --------- Revisiting $first and $last

// -- Quiz

Given the following collection:

> db.fun.find()
{ "_id" : 0, "a" : 0, "b" : 0, "c" : 21 }
{ "_id" : 1, "a" : 0, "b" : 0, "c" : 54 }
{ "_id" : 2, "a" : 0, "b" : 1, "c" : 52 }
{ "_id" : 3, "a" : 0, "b" : 1, "c" : 17 }
{ "_id" : 4, "a" : 1, "b" : 0, "c" : 22 }
{ "_id" : 5, "a" : 1, "b" : 0, "c" : 5 }
{ "_id" : 6, "a" : 1, "b" : 1, "c" : 87 }
{ "_id" : 7, "a" : 1, "b" : 1, "c" : 97 }

What would be the value of c in the result from this aggregation query

db.fun.aggregate([
    {$match:{a:0}},
    {$sort:{c:-1}},
    {$group:{_id:"$a", c:{$first:"$c"}}}
])

A. 54

// --------- Using $unwind

// -- Quiz

Suppose you have the following collection:

db.people.find()
{ "_id" : "Will", "likes" : [ "physics", "MongoDB", "indexes" ] }
{ "_id" : "Dwight", "likes" : [ "starting companies", "restaurants", "MongoDB" ] }

And you unwind the "likes" array of each document. How many documents will you wind up with?

A. 6

// --------- $unwind example

// -- Quiz

Which grouping operator will enable to you to reverse the effects of an unwind?

A. $push

// --------- Double $unwind

// -- Quiz

Can you reverse the effects of a double unwind (2 unwinds in a row) in our inventory collection (shown in the lesson ) with the $push operator?

A. Yes

// --------- Mapping between SQL and Aggregation

https://docs.mongodb.com/manual/reference/sql-aggregation-comparison/

// --------- Limitations of the Aggregation Framework

- 100 MB limit for pipeline stage. You can increase that using allowDiskUse option.
- 16 MB limit by default in Python
- Sharded -> When use something that requires looking all the data like $match or $sort, MongoDB is going to send all that data to the primary shard in order to everything be collected in one place. HADDOUP is the recommened guy for it.